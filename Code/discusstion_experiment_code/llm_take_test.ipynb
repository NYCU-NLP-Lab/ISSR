{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d7ed90d-215a-400d-b899-4c31c6e4bedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycliu/.conda/envs/FF/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "這份code請LLM做答學測題成績\n",
    "成果存於llm_test_performance\n",
    "內容包含: llm誤選的詞彙是誰、llm答錯的題目有哪些、整體答對率如何\n",
    "discusstion 6.2\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from models import openAIModel, vicunaModel, phi_2, zephyr\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from transformers import BertTokenizer, BertForMaskedLM, pipeline\n",
    "import numpy as np\n",
    "import fasttext\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from utils import *\n",
    "from openai import OpenAI\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from postprocess import self_answer\n",
    "import random\n",
    "import json\n",
    "from utils import *\n",
    "import json\n",
    "import re\n",
    "\n",
    "lemma_model = spacy.load('en_core_web_sm')\n",
    "ref_word = pd.read_excel(\"./dataset/高中英文參考詞彙表v2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "866c41db-a3e0-460c-808b-ff9e94acaa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "\n",
    "# Prepare model\n",
    "# client = Groq(\n",
    "#     api_key=\"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\"\n",
    "# )\n",
    "client = OpenAI(\n",
    "  api_key=\"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\",  # this is also the default, it can be omitted\n",
    ")\n",
    "\n",
    "# model = \"llama3-8b-8192\"\n",
    "# model = \"mixtral-8x7b-32768\"\n",
    "# model = \"gemma-7b-it\"\n",
    "model = \"llama3-70b-8192\"\n",
    "# model = \"gpt-3.5-turbo-1106\"\n",
    "# model = \"gpt-4-turbo-2024-04-09\"\n",
    "\n",
    "# Prepare data\n",
    "with open(\"./dataset/processed_gsat_data.json\", \"r\") as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dd950b0-3b2d-491b-93c3-a1aa9a622dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def prompt_preparation(question):\n",
    "    answer = question['answer'].lower()\n",
    "    prompt = f\"\"\"\n",
    "Imagine you are a high school student that studying english, and you are answering question given below:\n",
    "The following is a vocabulary test that requires selecting one answer from given options to fill in the blank.\n",
    "Please select the option that fit the context best from below, response with the correct word in option directly.\n",
    "\n",
    "Qustion:\n",
    "{{STEM}}\n",
    "\n",
    "options:\n",
    "{{OPTION1}}\n",
    "{{OPTION2}}\n",
    "{{OPTION3}}\n",
    "{{OPTION4}}\n",
    "\"\"\"\n",
    "    prompt = prompt.replace(\"{STEM}\", question['sentence'].replace(\"[MASK]\", \"_____\"))\n",
    "    options = question['distractors'].copy()\n",
    "    options.append(question['answer'])\n",
    "    random.shuffle(options)\n",
    "    prompt = prompt.replace(\"{OPTION1}\", options[0]).replace(\"{OPTION2}\", options[1]).replace(\"{OPTION3}\", options[2]).replace(\"{OPTION4}\", options[3])\n",
    "    return prompt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d438ef73-ba3d-4edf-85f7-edbb1e7ceb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "195it [04:11,  1.29s/it]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "correct_questions = []\n",
    "wrong_questions = []\n",
    "\n",
    "for index, i in tqdm(enumerate(dataset, 1)):\n",
    "    redo = False\n",
    "    while(True):\n",
    "        try:\n",
    "            prompt = prompt_preparation(i)\n",
    "            if(redo):\n",
    "                prompt = prompt + \"Please pick your response in the given four options only.\\n\"\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt,\n",
    "                    }\n",
    "                ],\n",
    "                model=model,\n",
    "            )\n",
    "            \n",
    "            response = chat_completion.choices[0].message.content\n",
    "            if i['answer'] in response:\n",
    "                correct_questions.append(index)\n",
    "            else:\n",
    "                wrong_answer = False\n",
    "                for dis in i['distractors']:\n",
    "                    if dis in response:\n",
    "                        wrong_questions.append((index, response))\n",
    "                        wrong_answer = True\n",
    "                        break\n",
    "                if not wrong_answer:\n",
    "                    redo = True\n",
    "                else:\n",
    "                    break\n",
    "                \n",
    "            break\n",
    "        # Request error, redo\n",
    "        except:\n",
    "            print(\"Redo request\")\n",
    "            time.sleep(2)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d7eb5ce0-e63e-4cbc-b4c3-d2d0e88d930f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "195it [06:28,  1.99s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM, pipeline\n",
    "\n",
    "correct_questions = []\n",
    "wrong_questions = []\n",
    "\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"AndyChiang/cdgp-csg-bert-cloth\")\n",
    "bert_csg_model = BertForMaskedLM.from_pretrained(\"AndyChiang/cdgp-csg-bert-cloth\")\n",
    "unmasker = pipeline('fill-mask', tokenizer=bert_tokenizer, model=bert_csg_model, top_k=2500)\n",
    "\n",
    "\n",
    "for index, i in tqdm(enumerate(dataset, 1)):\n",
    "    wrong_answer = False\n",
    "    prompt = f\"{i['sentence']} [SEP] f{i['answer']}\"\n",
    "    generated = list()\n",
    "    for cand in unmasker(prompt):\n",
    "        word = cand[\"token_str\"].replace(\" \", \"\").strip().lower()\n",
    "        generated.append(word)\n",
    "        if(len(generated) >50):\n",
    "            break\n",
    "        # word = cand[\"token_str\"].replace(\" \", \"\").strip().lower()\n",
    "        # if i['answer'].lower() == word:\n",
    "        #     correct_questions.append(index)\n",
    "        #     break\n",
    "        # else:\n",
    "        #     for dis in i['distractors']:\n",
    "        #         if dis.lower() == word:\n",
    "        #             wrong_questions.append((index, word))\n",
    "        #             wrong_answer = True\n",
    "        #             break\n",
    "        #     if not wrong_answer:\n",
    "        #         continue\n",
    "        #     else:\n",
    "        #         break\n",
    "    i['generated'] = generated[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "07e235de-0f81-41fa-aeff-6d5bf587fd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./result/bare_cdgp-csg-bert-cloth_no_filter.json\", \"w\") as f:\n",
    "    json.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e766ed9-0022-42c7-a299-1fc583c2354a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8974358974358975\n",
      "{'sentence': 'In winter, our skin tends to become dry and [MASK], a problem which is usually treated by applying lotions or creams.', 'answer': 'itchy', 'distractors': ['alert', 'steady', 'flexible']}\n",
      "flexible\n",
      "=======\n",
      "{'sentence': 'Mei-ling has a very close relationship with her parents. She always [MASK] them before she makes important decisions.', 'answer': 'consults', 'distractors': ['impresses', 'advises', 'motivates']}\n",
      "advises\n",
      "=======\n",
      "{'sentence': 'Emma and Joe are looking for a live-in babysitter for their three-year-old twins, [MASK] one who knows how to cook.', 'answer': 'preferably', 'distractors': ['initially', 'apparently', 'considerably']}\n",
      "apparently\n",
      "=======\n",
      "{'sentence': 'Jack is very proud of his fancy new motorcycle. He has been [MASK] to all his friends about how cool it looks and how fast it runs.', 'answer': 'boasting', 'distractors': ['proposing', 'gossiping', 'confessing']}\n",
      "proposing\n",
      "=======\n",
      "{'sentence': 'The chairperson of the meeting asked everyone to speak up instead of [MASK] their opinions among themselves.', 'answer': 'murmuring', 'distractors': ['reciting', 'giggling', 'whistling']}\n",
      "giggling\n",
      "=======\n",
      "{'sentence': 'Although Mr. Chen is rich, he is a very [MASK] person and is never willing to spend any money to help those who are in need.', 'answer': 'stingy', 'distractors': ['absolute', 'precise', 'economic']}\n",
      "absolute\n",
      "=======\n",
      "{'sentence': 'Everyone in our company enjoys working with Jason. He’s got all the qualities that make a [MASK] partner.', 'answer': 'desirable', 'distractors': ['comfortable', 'frequent', 'hostile']}\n",
      "comfortable\n",
      "=======\n",
      "{'sentence': 'Students were asked to [MASK] or rewrite their compositions based on the teacher’s comments. ', 'answer': 'revise', 'distractors': ['resign', 'refresh', 'remind']}\n",
      "resign\n",
      "=======\n",
      "{'sentence': 'Ruth is a very [MASK] person. She cannot take any criticism and always finds excuses to justify herself. ', 'answer': 'defensive', 'distractors': ['shameful', 'innocent', 'outgoing']}\n",
      "innocent\n",
      "=======\n",
      "{'sentence': 'Irene does not throw away used envelopes. She [MASK] them by using them for taking telephone messages.', 'answer': 'recycles', 'distractors': ['designs', 'disguises', 'manufactures']}\n",
      "manufactures\n",
      "=======\n",
      "{'sentence': 'Without much contact with the outside world for many years, John found many technological inventions [MASK] to him.', 'answer': 'foreign', 'distractors': ['natural', 'common', 'objective']}\n",
      "natural\n",
      "=======\n",
      "{'sentence': 'The medicine you take for a cold may cause [MASK]; try not to drive after you take it.', 'answer': 'drowsiness', 'distractors': ['incident', 'violence', 'bacteria']}\n",
      "violence\n",
      "=======\n",
      "{'sentence': 'Jessica is a very religious girl; she believes that she is always [MASK] supported by her god.', 'answer': 'spiritually', 'distractors': ['typically', 'historically', 'officially']}\n",
      "officially\n",
      "=======\n"
     ]
    }
   ],
   "source": [
    "# print(len(correct_questions))\n",
    "# print(len(wrong_questions))\n",
    "# print(wrong_questions)\n",
    "print(f\"accuracy: {len(correct_questions)/195}\")\n",
    "for i, j in wrong_questions:\n",
    "    print(dataset[i-1])\n",
    "    print(j, end=\"\\n=======\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6cea5e21-7822-4513-84f1-695cc3f4a6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8974358974358975, 'wrong_question_index': [11, 35, 60, 70, 72, 73, 78, 119, 144, 168, 177, 178, 189], 'wrong_response': ['flexible', 'advises', 'apparently', 'proposing', 'giggling', 'absolute', 'comfortable', 'resign', 'innocent', 'manufactures', 'natural', 'violence', 'officially']}\n"
     ]
    }
   ],
   "source": [
    "result = {\n",
    "    \"accuracy\": len(correct_questions)/195,\n",
    "    \"wrong_question_index\": [i for i, j in wrong_questions],\n",
    "    \"wrong_response\": [j for i, j in wrong_questions]\n",
    "}\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78f2391d-1f38-4b65-91d1-227784104f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./llm_test_performance/bert-large-uncased\", \"w\") as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7083475c-2da6-4936-96ae-15cba5354223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FF",
   "language": "python",
   "name": "ff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
