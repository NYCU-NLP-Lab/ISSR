{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'''HERE IS YOUR CONFIG - MODIFY IT IN CODE, NOT GUI'''\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ce3667d39b4506a08c3b6e59428da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Preprocess Mode: Select your candidate generator model', index=1, options=('None', 'CDGP…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fad604b6d6d41e39d7408296232df2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Enable Cheat: Randomly replace some generated candidates to ground truth\\n(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad7730f5f3f4f7794ce048a31414fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Zero-Shot Mode: Controls distractor selector zero-shot or few shot (true = …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb916f3d5444b48858408abc42e0454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Chain of Thought: Whether use CoT on distractor selector or not (set to fal…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adaac9c09279402294001021d272ce44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=50, description='Candidate Set Size: Size of candidate set', max=300, min=30, step=10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9eff688c354e5fbf6a2e975a362686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=3, description='Distractors per Round: Control distractors that picked by distractor selector …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd84753c4c30446482d8294f294001c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=30, description='Generate Count: Total required distractors from ISSR', min=10, step=10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a700e0380b0c44d4b3ae836271b48b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=True, description='Self Answer: Using self-review or not')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "953d3a3db14040629ed7ed71d8a342bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Error Report: Abandoned (set to false)')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e1b59469914b9ca64ed125e8f5aaf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='LLM Model: The LLM model used for distractor selector and self-reviewer\\ngroq-API / Open…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e91184409b4cf3adde05c743a879b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Device: your device', options=('cuda', 'cpu'), value='cuda')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Set the configuration here\n",
    "\"\"\"\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# input your API key here\n",
    "\n",
    "# openAI - for gpt\n",
    "API_KEY = \"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\"\n",
    "\n",
    "# groq - for llama3\n",
    "#API_KEY = \"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\"\n",
    "\n",
    "\n",
    "'''\n",
    "Candidate generator\n",
    "'''\n",
    "preprocess_mode = widgets.Dropdown(\n",
    "    options=['None', 'CDGP', 'BERT'], # in ISSR: CDGP\n",
    "    value='CDGP',\n",
    "    description='Preprocess Mode: Select your candidate generator model',\n",
    ")\n",
    "candidate_generator_top_k = widgets.IntSlider(\n",
    "    value=2500, # in ISSR: 2500\n",
    "    min=100,\n",
    "    max=4000,\n",
    "    step=10,\n",
    "    description='candidate_generator_top_k: How much candidates would be generated by candidate generator (this amount is BEFORE filter, make sure to be big)',\n",
    ")\n",
    "# if this is set to true, BERT model will not be load as candidate generator in runtime (mocked), not affecting performance\n",
    "use_cache_result = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Use cache result: Use cached candidate set generated by PLM (same stem+target word tends to generate same result)'\n",
    ")\n",
    "# candidate set cache location, used for \"use_cache_result\"\n",
    "# CAUTION: Make sure to select the correct file for caching: *BERT_response_cache* contains results generated by BERT, whereas *CDGP_response_cache* contains results generated by CDGP.\n",
    "# CAUTION: Your sanpai me, forgot to select the correct file for experience, leading to poor performance for months until I finally discovered the issue...\n",
    "candidate_set_cache_path = \"./dataset/BERT_response_cache.json\"\n",
    "\n",
    "\n",
    "cheat = widgets.Checkbox(\n",
    "    value=False, # in ISSR: false\n",
    "    description='''Enable Cheat: Randomly replace some generated candidates to ground truth\n",
    "(to ensure ground truth exists in the candidate set)'''\n",
    ")\n",
    "\n",
    "candidate_set_size = widgets.IntSlider(\n",
    "    value=50, # in ISSR: 50\n",
    "    min=30,\n",
    "    max=300,\n",
    "    step=10,\n",
    "    description='Candidate Set Size: Size of candidate set'\n",
    ")\n",
    "\n",
    "\n",
    "'''\n",
    "Distractor selector\n",
    "'''\n",
    "zero_shot = widgets.Checkbox(\n",
    "    value=False, # in ISSR: false\n",
    "    description='Zero-Shot Mode: Controls distractor selector zero-shot or few shot (true = zeroshot, false=fewshot)'\n",
    ")\n",
    "\n",
    "chain_of_thought = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Chain of Thought: Whether use CoT on distractor selector or not (set to false)' \n",
    ")\n",
    "\n",
    "\n",
    "pick_distractors_per_round = widgets.IntSlider(\n",
    "    value=3, # Best: 3\n",
    "    min=3,\n",
    "    max=30,\n",
    "    step=5,\n",
    "    description='Distractors per Round: Control distractors that picked by distractor selector per round'\n",
    ")\n",
    "\n",
    "\n",
    "'''\n",
    "Self-review\n",
    "'''\n",
    "\n",
    "self_review = widgets.Checkbox(\n",
    "    value=True, # in ISSR: true\n",
    "    description='Self Answer: Using self-review or not'\n",
    ")\n",
    "\n",
    "error_report = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Error Report: Abandoned (set to false)'\n",
    ")\n",
    "\n",
    "\n",
    "'''\n",
    "Overall\n",
    "'''\n",
    "\n",
    "LLM = widgets.Dropdown(\n",
    "    options=['gpt', 'gemma2', 'llama3_8b', 'llama3_70b'],\n",
    "    value='gpt', # in ISSR: gpt\n",
    "    description='''LLM Model: The LLM model used for distractor selector and self-reviewer\n",
    "groq-API / OpenAI api required for models.'''\n",
    ")\n",
    "\n",
    "model_name = widgets.Dropdown(\n",
    "    options=['gpt-4-turbo-2024-04-09', 'gpt-3.5-turbo-0125', 'llama3-70b-8192',\n",
    "             'llama3-8b-8192', 'gpt-4o-mini-2024-07-18'],\n",
    "    value='gpt-3.5-turbo-0125', # in ISSR: gpt-3.5-turbo-0125\n",
    "    description='LLM Model: Specify LLM.'\n",
    ")\n",
    "\n",
    "generate_count = widgets.IntSlider(\n",
    "    value=30, # in ISSR: 30\n",
    "    min=10,\n",
    "    max=100,\n",
    "    step=10,\n",
    "    description='Generate Count: Total required distractors from ISSR'\n",
    ")\n",
    "\n",
    "device = widgets.Dropdown(\n",
    "    options=['cuda', 'cpu'],\n",
    "    value='cuda',\n",
    "    description='Device: your device'\n",
    ")\n",
    "\n",
    "\n",
    "record_bad_distractor = widgets.Checkbox(\n",
    "    value=True, # for recording bad distractors, not affecting performance\n",
    "    description='Record bad distractor: Record select history of distractor selector'\n",
    ")\n",
    "\n",
    "# location of rule-based reference datas\n",
    "# CEEC word list\n",
    "ref_vocabulary_path = \"../Dataset/高中英文參考詞彙表v2.xlsx\"\n",
    "# GSAT questions (or questions required to generate distractors)\n",
    "dataset_path = \"../Dataset/processed_gsat_data.json\"\n",
    "# english dictionary list, which records all english vocabulary (used to test whether the generated candidate is a vocabulary or not)\n",
    "english_dictionary_list_path = \"../Dataset/words_alpha.txt\"\n",
    "\n",
    "\n",
    "print(\"'''HERE IS YOUR CONFIG - MODIFY IT IN CODE, NOT GUI'''\")\n",
    "display(preprocess_mode, cheat, zero_shot, chain_of_thought, candidate_set_size,\n",
    "        pick_distractors_per_round, generate_count, self_review, error_report, LLM, device)\n",
    "\n",
    "\n",
    "def get_config():\n",
    "    config = {\n",
    "        \"preprocess_function\": {\n",
    "            \"mode\": preprocess_mode.value,\n",
    "            \"reason\": \"gpt\", # this is abandoned, let it be\n",
    "            \"cheat\": cheat.value\n",
    "        },\n",
    "        \"distractor_generation_function\": {\n",
    "            \"zero-shot\": zero_shot.value,\n",
    "            \"chain_of_thought\": chain_of_thought.value,\n",
    "            \"candidate_set_size\": candidate_set_size.value,\n",
    "            \"pick_distractors_per_round\": pick_distractors_per_round.value,\n",
    "            \"generate_count\": generate_count.value,\n",
    "        },\n",
    "        \"post_processing_function\": {\n",
    "            \"self-answer\": self_review.value,\n",
    "            \"error-report\": error_report.value,\n",
    "            \"generate_count\": generate_count.value\n",
    "        },\n",
    "        \"api_key\": API_KEY,\n",
    "        \"use_cache_result\": use_cache_result.value,\n",
    "        \"LLM\": LLM.value,\n",
    "        \"model_name\": model_name.value,\n",
    "        \"device\": device.value,\n",
    "        \"ref_vocabulary_path\": ref_vocabulary_path,\n",
    "        \"dataset_path\": dataset_path,\n",
    "        \"english_dictionary_list_path\": english_dictionary_list_path,\n",
    "        \"candidate_set_cache_path\": candidate_set_cache_path,\n",
    "        \"candidate_generator_top_k\": candidate_generator_top_k.value,\n",
    "        \"record_bad_distractor\": True\n",
    "    }\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from models import openAIModel, gemma2, llama3_8b, llama3_70b\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from transformers import BertTokenizer, BertForMaskedLM, pipeline\n",
    "import numpy as np\n",
    "import fasttext\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from utils import *\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from postprocess import self_answer, self_answer_correctness, self_answer_same_meaning\n",
    "import random\n",
    "from openai import OpenAI\n",
    "\n",
    "class DistractorGenerationModel:\n",
    "    def __init__(\n",
    "            self, \n",
    "            config,\n",
    "            preprocess_function,\n",
    "            distractor_generation_function,\n",
    "            post_processing_function,\n",
    "        ):\n",
    "        with open(config['dataset_path'], \"r\") as f:\n",
    "            self.dataset = json.load(f)\n",
    "            # skip the fewshoted question\n",
    "            self.dataset = self.dataset[2:]\n",
    "        self.config = config\n",
    "        self.ref_word = pd.read_excel(config['ref_vocabulary_path'])\n",
    "        # Load words dictionary for distractor generation filter\n",
    "        file_path = config['english_dictionary_list_path']  # Replace \"your_file.txt\" with the path to your text file\n",
    "        self.word_list = []\n",
    "        with open(file_path, 'r') as file:\n",
    "            # Read each line and append it to the list\n",
    "            for line in file:\n",
    "                self.word_list.append(line.strip())  # Strip any leading/trailing whitespace or newline characters\n",
    "        \n",
    "\n",
    "        \n",
    "        # Choose the LLM to inference\n",
    "        if config['LLM'] == \"gpt\":\n",
    "            # Model name is used for LLM templates\n",
    "            self.model = openAIModel(config['api_key'])\n",
    "            self.model_name = \"gpt\"\n",
    "        elif config['LLM'] == \"llama3_8b\":\n",
    "            self.model_name = \"llama3_8b\"\n",
    "            self.model = llama3_8b(config['api_key'])\n",
    "        elif config['LLM'] == \"llama3_70b\":\n",
    "            self.model_name = \"llama3_70b\"\n",
    "            self.model = llama3_70b(config['api_key'])\n",
    "        elif config['LLM'] == \"gemma2\":\n",
    "            self.model_name = \"gemma2\"\n",
    "            self.model = gemma2(config['api_key'])\n",
    "\n",
    "        \n",
    "        self.lemma_model = spacy.load('en_core_web_sm')\n",
    "        # Ready BERT\n",
    "        if (config['preprocess_function']['mode'] == \"BERT\" or config['preprocess_function']['mode'] == \"both\") and config['use_cache_result'] == False:\n",
    "            print(\"Loading BERT as candidate generator...\")\n",
    "            self.bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "            self.bert_csg_model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "            self.unmasker = pipeline('fill-mask', tokenizer=self.bert_tokenizer, model=self.bert_csg_model, top_k=config['candidate_generator_top_k'])\n",
    "        elif (config['preprocess_function']['mode'] == \"CDGP\" or config['preprocess_function']['mode'] == \"both\"):\n",
    "            print(\"Loading cdgp-csg-bert as candidate generator...\")\n",
    "            self.bert_tokenizer = BertTokenizer.from_pretrained(\"AndyChiang/cdgp-csg-bert-cloth\")\n",
    "            self.bert_csg_model = BertForMaskedLM.from_pretrained(\"AndyChiang/cdgp-csg-bert-cloth\")\n",
    "            self.unmasker = pipeline('fill-mask', tokenizer=self.bert_tokenizer, model=self.bert_csg_model, top_k=config['candidate_generator_top_k'])\n",
    "        self.preprocess_function = preprocess_function\n",
    "        self.distractor_generation_function = distractor_generation_function\n",
    "        self.post_processing_function = post_processing_function\n",
    "\n",
    "    # filter list of candidates given predefined rules\n",
    "    def _filter_good_cand(self, cs, question):\n",
    "        filtered_cs = list()\n",
    "        for c in cs:\n",
    "            if self._has_same_postag(c, question) and self._has_sim_length(c, question) and self._has_sim_difficulty(c, question):\n",
    "                filtered_cs.append(c)\n",
    "        return filtered_cs\n",
    "\n",
    "\n",
    "    def _has_sim_length(self, gen_distractor, question):\n",
    "        ans_len = len(question['answer'])\n",
    "        if(ans_len - len(gen_distractor) > 2):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def _has_same_postag(self, gen_distractor, question):\n",
    "        \n",
    "        sentence = question['sentence']\n",
    "        answer = question['answer']\n",
    "        ans_pos_tag = get_pos_tag_of_word(sentence, answer)\n",
    "        if(get_pos_tag_of_word(sentence, gen_distractor) != ans_pos_tag):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "\n",
    "    def _has_sim_difficulty(self, gen_distractor, question):\n",
    "        ref_word = self.ref_word.copy()\n",
    "        ref_word.set_index('單字', inplace=True)\n",
    "        answer = question['answer']\n",
    "        answer = lemmatization(answer, self.lemma_model)\n",
    "        result = ref_word[ref_word.index == answer]\n",
    "        if result.empty:\n",
    "            # print(\"WARNING, answer not in ref word list\")\n",
    "            # print(f\"question: {question['sentence']}\")\n",
    "            return True\n",
    "        else:\n",
    "            ans_dif = result['難度'].values[0]\n",
    "\n",
    "        gen_distractor = lemmatization(gen_distractor, self.lemma_model)\n",
    "        result = ref_word[ref_word.index == gen_distractor]\n",
    "        if result.empty:\n",
    "            return False\n",
    "        else:\n",
    "            if(abs(result['難度'].values[0]-ans_dif) > 1):\n",
    "                return False\n",
    "            return True\n",
    "\n",
    "\n",
    "    def extract_response(self, response, cand_pool = None):\n",
    "        # remove ' \" in response\n",
    "        response = response.replace(\"'\", \"\").replace('\"', \"\").strip()\n",
    "        if self.model_name == 'zephyr':\n",
    "          pattern = re.compile(\"\\d+\\. \")\n",
    "          response = [x.lower().replace(\"\\\"\", \"\") for x in pattern.sub(\"\", response).strip().split(\"\\n\") if x != \"\"]\n",
    "        elif self.model_name == 'vicuna-1.5-original':\n",
    "          pattern = re.compile(\"\\d+\\. \")\n",
    "          response = [x.lower().replace(\"\\\"\", \"\") for x in pattern.sub(\"\", response).strip().split(\"\\n\") if x != \"\"]\n",
    "        elif 'gpt' in self.model_name:\n",
    "          pattern = re.compile(\"\\d+\\. \")\n",
    "          response = [x.lower().replace(\"\\\"\", \"\") for x in pattern.sub(\"\", response).strip().split(\"\\n\") if x != \"\"]\n",
    "        else:\n",
    "          pattern = re.compile(\"\\d+\\. \")\n",
    "          response = [x.lower().replace(\"\\\"\", \"\") for x in pattern.sub(\"\", response).strip().split(\"\\n\") if x != \"\"]\n",
    "        response = list(set(response))\n",
    "        # Further process output by checking whether it exist in english dictionary or not\n",
    "        new_response = []\n",
    "        for i in response:\n",
    "            # check if the response vocabulary exists in english dictionary(dataset/words_alpha)\n",
    "            if i.strip().lower() not in self.word_list:\n",
    "                pass\n",
    "            else:\n",
    "                new_response.append(i.strip().lower())\n",
    "                \n",
    "        # Further process output by checking wheher it exist in candidate set\n",
    "        # if cand_pool is not None:\n",
    "        #     cand_pool = [x.lower().strip() for x in cand_pool]\n",
    "        #     final_response=[]\n",
    "        #     for i in new_response:\n",
    "        #         if i.strip().lower() in cand_pool:\n",
    "        #             final_response.append(i.strip())\n",
    "        #         else:\n",
    "        #             pass\n",
    "        #     new_response = final_response\n",
    "        return new_response\n",
    "    \n",
    "    def recall_rate_of_top_k(self, k):\n",
    "        recall_total = list()\n",
    "        for question in self.dataset:\n",
    "            match = 0\n",
    "            pool = self.preprocess_function(self, question)['cand_pool'][:k]\n",
    "            if len(pool) < k:\n",
    "                print(f\"Warning: Valid distractor set size is lower than {k}\")\n",
    "            for d in question['distractors']:\n",
    "                if d in pool:\n",
    "                    match+=1\n",
    "                recall_total.append(match)\n",
    "        return (sum(recall_total)/len(recall_total))/3\n",
    "\n",
    "    def run_framework(self):\n",
    "        self.result = []\n",
    "        self.overall_generate_history = []\n",
    "        self.bert_result = list()\n",
    "\n",
    "\n",
    "        if config['preprocess_function']['mode'] == \"BERT\" and config['use_cache_result'] == True:\n",
    "            with open(config['candidate_set_cache_path'], \"r\") as f:\n",
    "                fastdata = json.load(f)\n",
    "        if config['preprocess_function']['mode'] == \"CDGP\" and config['use_cache_result'] == True:\n",
    "            with open(config['candidate_set_cache_path'], \"r\") as f:\n",
    "                fastdata = json.load(f)\n",
    "        \n",
    "        for ind, question in enumerate(self.dataset):\n",
    "            print(ind)\n",
    "            # The passed distractor\n",
    "            self.good_distractor = []\n",
    "            # The bad distractor in this question\n",
    "            self.persist_bad_distractor = []\n",
    "            # The bad distractor in this round of picking\n",
    "            self.bad_distractor = []\n",
    "            # Do the preprocess part (generation of candidate set using BERT)\n",
    "            if (config['preprocess_function']['mode'] == \"BERT\" or config['preprocess_function']['mode'] == \"CDGP\") and config['use_cache_result'] == True:\n",
    "                prompt_pool = {\n",
    "                    \"reason\": None,\n",
    "                    \"cand_pool\": fastdata[ind]\n",
    "                }\n",
    "                candidate_size = self.config[\"distractor_generation_function\"][\"candidate_set_size\"]\n",
    "                prompt_pool['cand_pool'] = prompt_pool['cand_pool'][:candidate_size]\n",
    "            else:\n",
    "                prompt_pool = self.preprocess_function(self, question)\n",
    "                candidate_size = self.config[\"distractor_generation_function\"][\"candidate_set_size\"]\n",
    "                if(prompt_pool.get('cand_pool') is not None):\n",
    "                    prompt_pool['cand_pool'] = prompt_pool['cand_pool'][:candidate_size]\n",
    "\n",
    "\n",
    "            \n",
    "            # cheat: decrease the size of cand_pool to K which contains the ground truth\n",
    "            if config['preprocess_function']['cheat'] == True:\n",
    "                # Cut the size of cand_pool into K\n",
    "                prompt_pool['cand_pool'] = prompt_pool['cand_pool'][:10]\n",
    "                # randomly replace three distractors candidate to ground truth\n",
    "                numbers_range = list(range(0, min(len(prompt_pool['cand_pool']), 30)))\n",
    "                unique_numbers = random.sample(numbers_range, 3)\n",
    "                ground_truth = question['distractors']\n",
    "                for uni, dis in zip(unique_numbers, ground_truth):\n",
    "                    prompt_pool['cand_pool'][uni] = dis\n",
    "            # Do the distractor generation part\n",
    "            if ind == 0:\n",
    "                # Print prompt\n",
    "                distractor_pool = self.distractor_generation_function(self, question, prompt_pool, sample=True)\n",
    "            else:\n",
    "                distractor_pool = self.distractor_generation_function(self, question, prompt_pool, sample=False)\n",
    "            \n",
    "            \n",
    "            if self.config[\"post_processing_function\"]['self-answer'] == False:\n",
    "                question['generated'] = distractor_pool\n",
    "                continue\n",
    "            \n",
    "            # Self-answer\n",
    "            self.post_processing_function(self, question, distractor_pool)\n",
    "            generate_history = []\n",
    "            t = []\n",
    "            for g in self.good_distractor:\n",
    "                t.append(g)\n",
    "            for b in self.bad_distractor:\n",
    "                t.append(b)\n",
    "            generate_history.append(t)\n",
    "            # Retry to generate distractors for at most 'tries' time\n",
    "            tries = 0\n",
    "            while len(self.good_distractor) < self.config['post_processing_function']['generate_count'] and tries < 2:\n",
    "                tries+=1\n",
    "                if(self.config[\"post_processing_function\"][\"self-answer\"] == True):\n",
    "                    for d in self.bad_distractor:\n",
    "                        if self.config[\"preprocess_function\"]['mode'] != \"None\" and d in prompt_pool['cand_pool']:\n",
    "                            prompt_pool['cand_pool'].remove(d)\n",
    "                    for d in self.good_distractor:\n",
    "                        if self.config[\"preprocess_function\"]['mode'] != \"None\" and d in prompt_pool['cand_pool']:\n",
    "                            prompt_pool['cand_pool'].remove(d)\n",
    "                for d in self.bad_distractor:\n",
    "                    self.persist_bad_distractor.append(d)\n",
    "                    \n",
    "                t = []\n",
    "                for g in self.good_distractor:\n",
    "                    t.append(g)\n",
    "                for b in self.bad_distractor:\n",
    "                    t.append(b)\n",
    "                generate_history.append(t)\n",
    "            \n",
    "                self.bad_distractor = []\n",
    "                distractor_pool = self.distractor_generation_function(self, question, prompt_pool)\n",
    "                self.post_processing_function(self, question, distractor_pool)\n",
    "\n",
    "            # if good distractor is less then 3, append previous bad distractors to the result\n",
    "            self.persist_bad_distractor = list(set(self.persist_bad_distractor))\n",
    "            for d in self.persist_bad_distractor:\n",
    "                if(len(self.good_distractor) < self.config['post_processing_function']['generate_count']):\n",
    "                    self.good_distractor.append(d)\n",
    "                else:\n",
    "                    break\n",
    "            if len(self.good_distractor) < self.config['post_processing_function']['generate_count']:\n",
    "                # The generated distractor is still less then 3\n",
    "                question['generated'] = self.good_distractor\n",
    "            else:\n",
    "                question['generated'] = self.good_distractor[:self.config['post_processing_function']['generate_count']]\n",
    "            self.overall_generate_history.append(generate_history)\n",
    "            generate_history = []\n",
    "        return\n",
    "        #return self.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'preprocess_function': {'mode': 'CDGP', 'reason': 'gpt', 'cheat': False}, 'distractor_generation_function': {'zero-shot': False, 'chain_of_thought': False, 'candidate_set_size': 50, 'pick_distractors_per_round': 3, 'generate_count': 30}, 'post_processing_function': {'self-answer': True, 'error-report': False, 'generate_count': 30}, 'api_key': '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', 'use_cache_result': False, 'LLM': 'gpt', 'model_name': 'gpt-3.5-turbo-0125', 'device': 'cuda', 'ref_vocabulary_path': '../Dataset/高中英文參考詞彙表v2.xlsx', 'dataset_path': '../Dataset/processed_gsat_data.json', 'english_dictionary_list_path': '../Dataset/words_alpha.txt', 'candidate_set_cache_path': './dataset/BERT_response_cache.json', 'candidate_generator_top_k': 2500, 'record_bad_distractor': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ycliu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ycliu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/ycliu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/ycliu/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cdgp-csg-bert as candidate generator...\n",
      "0\n",
      "Prompt Example:\n",
      "[{'role': 'user', 'content': '**Original Sentence**\\nPosters of the local rock band were displayed in store windows to promote the sale of their _____ tickets.\\n\\n**Target Word**\\nconcert\\n\\n**Candidate Pool**\\n\"sports\", \"proper\", \"regular\", \"personal\", \"clothes\", \"favorite\", \"traffic\", \"traditional\", \"valuable\", \"available\", \"travel\", \"necessary\", \"fashionable\", \"record\", \"official\", \"final\", \"usual\", \"clothing\", \"educational\", \"fashion\", \"journey\"\\n\\npick three distractors from **Candidate Pool** for stem given in Original Sentence, response each distractors per line, and starts with enumerate number'}, {'role': 'assistant', 'content': '1. journey\\n2. traffic\\n3. record'}, {'role': 'user', 'content': '**Original Sentence**\\nMaria didn\\'t want to deliver the bad news to David about his failing the job interview. She herself was quite _____ about it.\\n\\n**Target Word**\\nupset\\n\\n**Candidate Pool**\\n\"curious\", \"careful\", \"excited\", \"happy\", \"afraid\", \"drowsy\", \"interested\", \"serious\", \"nervous\", \"concerned\", \"angry\", \"crazy\", \"sorry\", \"awful\", \"tired\", \"sure\", \"surprised\", \"upset\", \"good\", \"honest\", \"tragic\", \"terrible\", \"proud\", \"scared\", \"pleased\", \"strict\"\\n  \\npick three distractors from **Candidate Pool** for stem given in Original Sentence, response each distractors per line, and starts with enumerate number\\n'}, {'role': 'assistant', 'content': '1. awful\\n2. drowsy\\n3. tragic'}, {'role': 'user', 'content': \"**Original Sentence**\\n    The newcomer speaks with a strong Irish _____; he must be from Ireland.\\n    \\n**Target Word**\\naccent\\n    \\n\\n**Candidate Pool**\\n'jazz', 'concept', 'rate', 'desire', 'accents', 'warning', 'chat', 'performance', 'talent', 'complaint', 'faith', 'presence', 'usage', 'signature', 'vocabulary', 'yell', 'background', 'warmth', 'rush', 'confidence', 'behavior', 'remark', 'tune', 'characteristic', 'dialect', 'version', 'whistle', 'comment', 'explanation', 'theme', 'response', 'variety', 'flavor', 'suggestion', 'humor', 'impression', 'strength', 'cough', 'rhythm', 'pace', 'scream', 'grammar', 'laughter', 'sigh', 'signal', 'breath', 'gesture', 'attitude', 'pronunciation', 'accent'\\n\\npick 3 distractors from **Candidate Pool** section for stem given in Original Sentence, response each distractors per line, and starts with enumerate number. Please select your response from words in section **Candidate Pool** only.\"}]\n",
      "Now inferencing with gpt-3.5-turbo-0125\n",
      "Assistent: 1. dialect\n",
      "2. rhythm\n",
      "3. signature\n",
      "Prompt Example:\n",
      "[{'role': 'user', 'content': '**Original Sentence**\\nPosters of the local rock band were displayed in store windows to promote the sale of their _____ tickets.\\n\\n**Target Word**\\nconcert\\n\\n**Candidate Pool**\\n\"sports\", \"proper\", \"regular\", \"personal\", \"clothes\", \"favorite\", \"traffic\", \"traditional\", \"valuable\", \"available\", \"travel\", \"necessary\", \"fashionable\", \"record\", \"official\", \"final\", \"usual\", \"clothing\", \"educational\", \"fashion\", \"journey\"\\n\\npick three distractors from **Candidate Pool** for stem given in Original Sentence, response each distractors per line, and starts with enumerate number'}, {'role': 'assistant', 'content': '1. journey\\n2. traffic\\n3. record'}, {'role': 'user', 'content': '**Original Sentence**\\nMaria didn\\'t want to deliver the bad news to David about his failing the job interview. She herself was quite _____ about it.\\n\\n**Target Word**\\nupset\\n\\n**Candidate Pool**\\n\"curious\", \"careful\", \"excited\", \"happy\", \"afraid\", \"drowsy\", \"interested\", \"serious\", \"nervous\", \"concerned\", \"angry\", \"crazy\", \"sorry\", \"awful\", \"tired\", \"sure\", \"surprised\", \"upset\", \"good\", \"honest\", \"tragic\", \"terrible\", \"proud\", \"scared\", \"pleased\", \"strict\"\\n  \\npick three distractors from **Candidate Pool** for stem given in Original Sentence, response each distractors per line, and starts with enumerate number\\n'}, {'role': 'assistant', 'content': '1. awful\\n2. drowsy\\n3. tragic'}, {'role': 'user', 'content': \"**Original Sentence**\\n    The newcomer speaks with a strong Irish _____; he must be from Ireland.\\n    \\n**Target Word**\\naccent\\n    \\n\\n**Candidate Pool**\\n'jazz', 'concept', 'rate', 'desire', 'accents', 'warning', 'chat', 'performance', 'talent', 'complaint', 'faith', 'presence', 'usage', 'vocabulary', 'yell', 'background', 'warmth', 'rush', 'confidence', 'behavior', 'remark', 'tune', 'characteristic', 'version', 'whistle', 'comment', 'explanation', 'theme', 'response', 'variety', 'flavor', 'suggestion', 'humor', 'impression', 'strength', 'cough', 'pace', 'scream', 'grammar', 'laughter', 'sigh', 'signal', 'breath', 'gesture', 'attitude', 'pronunciation', 'accent'\\n\\npick 3 distractors from **Candidate Pool** section for stem given in Original Sentence, response each distractors per line, and starts with enumerate number. Please select your response from words in section **Candidate Pool** only.\"}]\n",
      "Assistent: 1. performance\n",
      "2. behavior\n",
      "3. strength\n",
      "Prompt Example:\n",
      "[{'role': 'user', 'content': '**Original Sentence**\\nPosters of the local rock band were displayed in store windows to promote the sale of their _____ tickets.\\n\\n**Target Word**\\nconcert\\n\\n**Candidate Pool**\\n\"sports\", \"proper\", \"regular\", \"personal\", \"clothes\", \"favorite\", \"traffic\", \"traditional\", \"valuable\", \"available\", \"travel\", \"necessary\", \"fashionable\", \"record\", \"official\", \"final\", \"usual\", \"clothing\", \"educational\", \"fashion\", \"journey\"\\n\\npick three distractors from **Candidate Pool** for stem given in Original Sentence, response each distractors per line, and starts with enumerate number'}, {'role': 'assistant', 'content': '1. journey\\n2. traffic\\n3. record'}, {'role': 'user', 'content': '**Original Sentence**\\nMaria didn\\'t want to deliver the bad news to David about his failing the job interview. She herself was quite _____ about it.\\n\\n**Target Word**\\nupset\\n\\n**Candidate Pool**\\n\"curious\", \"careful\", \"excited\", \"happy\", \"afraid\", \"drowsy\", \"interested\", \"serious\", \"nervous\", \"concerned\", \"angry\", \"crazy\", \"sorry\", \"awful\", \"tired\", \"sure\", \"surprised\", \"upset\", \"good\", \"honest\", \"tragic\", \"terrible\", \"proud\", \"scared\", \"pleased\", \"strict\"\\n  \\npick three distractors from **Candidate Pool** for stem given in Original Sentence, response each distractors per line, and starts with enumerate number\\n'}, {'role': 'assistant', 'content': '1. awful\\n2. drowsy\\n3. tragic'}, {'role': 'user', 'content': \"**Original Sentence**\\n    The newcomer speaks with a strong Irish _____; he must be from Ireland.\\n    \\n**Target Word**\\naccent\\n    \\n\\n**Candidate Pool**\\n'jazz', 'concept', 'rate', 'desire', 'accents', 'warning', 'chat', 'talent', 'complaint', 'faith', 'presence', 'usage', 'vocabulary', 'yell', 'background', 'warmth', 'rush', 'confidence', 'remark', 'tune', 'characteristic', 'version', 'whistle', 'comment', 'explanation', 'theme', 'response', 'variety', 'flavor', 'suggestion', 'humor', 'impression', 'cough', 'pace', 'scream', 'grammar', 'laughter', 'sigh', 'signal', 'breath', 'gesture', 'attitude', 'pronunciation', 'accent'\\n\\npick 3 distractors from **Candidate Pool** section for stem given in Original Sentence, response each distractors per line, and starts with enumerate number. Please select your response from words in section **Candidate Pool** only.\"}]\n",
      "Assistent: 1. concept\n",
      "2. rate\n",
      "3. vocabulary\n",
      "Prompt Example:\n",
      "[{'role': 'user', 'content': '**Original Sentence**\\nPosters of the local rock band were displayed in store windows to promote the sale of their _____ tickets.\\n\\n**Target Word**\\nconcert\\n\\n**Candidate Pool**\\n\"sports\", \"proper\", \"regular\", \"personal\", \"clothes\", \"favorite\", \"traffic\", \"traditional\", \"valuable\", \"available\", \"travel\", \"necessary\", \"fashionable\", \"record\", \"official\", \"final\", \"usual\", \"clothing\", \"educational\", \"fashion\", \"journey\"\\n\\npick three distractors from **Candidate Pool** for stem given in Original Sentence, response each distractors per line, and starts with enumerate number'}, {'role': 'assistant', 'content': '1. journey\\n2. traffic\\n3. record'}, {'role': 'user', 'content': '**Original Sentence**\\nMaria didn\\'t want to deliver the bad news to David about his failing the job interview. She herself was quite _____ about it.\\n\\n**Target Word**\\nupset\\n\\n**Candidate Pool**\\n\"curious\", \"careful\", \"excited\", \"happy\", \"afraid\", \"drowsy\", \"interested\", \"serious\", \"nervous\", \"concerned\", \"angry\", \"crazy\", \"sorry\", \"awful\", \"tired\", \"sure\", \"surprised\", \"upset\", \"good\", \"honest\", \"tragic\", \"terrible\", \"proud\", \"scared\", \"pleased\", \"strict\"\\n  \\npick three distractors from **Candidate Pool** for stem given in Original Sentence, response each distractors per line, and starts with enumerate number\\n'}, {'role': 'assistant', 'content': '1. awful\\n2. drowsy\\n3. tragic'}, {'role': 'user', 'content': \"**Original Sentence**\\n    The newcomer speaks with a strong Irish _____; he must be from Ireland.\\n    \\n**Target Word**\\naccent\\n    \\n\\n**Candidate Pool**\\n'jazz', 'desire', 'accents', 'warning', 'chat', 'talent', 'complaint', 'faith', 'presence', 'usage', 'yell', 'background', 'warmth', 'rush', 'confidence', 'remark', 'tune', 'characteristic', 'version', 'whistle', 'comment', 'explanation', 'theme', 'response', 'variety', 'flavor', 'suggestion', 'humor', 'impression', 'cough', 'pace', 'scream', 'grammar', 'laughter', 'sigh', 'signal', 'breath', 'gesture', 'attitude', 'pronunciation', 'accent'\\n\\npick 3 distractors from **Candidate Pool** section for stem given in Original Sentence, response each distractors per line, and starts with enumerate number. Please select your response from words in section **Candidate Pool** only.\"}]\n",
      "Assistent: 1. jazz\n",
      "2. complaint\n",
      "3. whistle\n",
      "Prompt Example:\n",
      "[{'role': 'user', 'content': '**Original Sentence**\\nPosters of the local rock band were displayed in store windows to promote the sale of their _____ tickets.\\n\\n**Target Word**\\nconcert\\n\\n**Candidate Pool**\\n\"sports\", \"proper\", \"regular\", \"personal\", \"clothes\", \"favorite\", \"traffic\", \"traditional\", \"valuable\", \"available\", \"travel\", \"necessary\", \"fashionable\", \"record\", \"official\", \"final\", \"usual\", \"clothing\", \"educational\", \"fashion\", \"journey\"\\n\\npick three distractors from **Candidate Pool** for stem given in Original Sentence, response each distractors per line, and starts with enumerate number'}, {'role': 'assistant', 'content': '1. journey\\n2. traffic\\n3. record'}, {'role': 'user', 'content': '**Original Sentence**\\nMaria didn\\'t want to deliver the bad news to David about his failing the job interview. She herself was quite _____ about it.\\n\\n**Target Word**\\nupset\\n\\n**Candidate Pool**\\n\"curious\", \"careful\", \"excited\", \"happy\", \"afraid\", \"drowsy\", \"interested\", \"serious\", \"nervous\", \"concerned\", \"angry\", \"crazy\", \"sorry\", \"awful\", \"tired\", \"sure\", \"surprised\", \"upset\", \"good\", \"honest\", \"tragic\", \"terrible\", \"proud\", \"scared\", \"pleased\", \"strict\"\\n  \\npick three distractors from **Candidate Pool** for stem given in Original Sentence, response each distractors per line, and starts with enumerate number\\n'}, {'role': 'assistant', 'content': '1. awful\\n2. drowsy\\n3. tragic'}, {'role': 'user', 'content': \"**Original Sentence**\\n    The newcomer speaks with a strong Irish _____; he must be from Ireland.\\n    \\n**Target Word**\\naccent\\n    \\n\\n**Candidate Pool**\\n'desire', 'accents', 'warning', 'chat', 'talent', 'faith', 'presence', 'usage', 'yell', 'background', 'warmth', 'rush', 'confidence', 'remark', 'tune', 'characteristic', 'version', 'comment', 'explanation', 'theme', 'response', 'variety', 'flavor', 'suggestion', 'humor', 'impression', 'cough', 'pace', 'scream', 'grammar', 'laughter', 'sigh', 'signal', 'breath', 'gesture', 'attitude', 'pronunciation', 'accent'\\n\\npick 3 distractors from **Candidate Pool** section for stem given in Original Sentence, response each distractors per line, and starts with enumerate number. Please select your response from words in section **Candidate Pool** only.\"}]\n",
      "Assistent: 1. attitude\n",
      "2. grammar\n",
      "3. pronunciation\n",
      "Prompt Example:\n",
      "[{'role': 'user', 'content': '**Original Sentence**\\nPosters of the local rock band were displayed in store windows to promote the sale of their _____ tickets.\\n\\n**Target Word**\\nconcert\\n\\n**Candidate Pool**\\n\"sports\", \"proper\", \"regular\", \"personal\", \"clothes\", \"favorite\", \"traffic\", \"traditional\", \"valuable\", \"available\", \"travel\", \"necessary\", \"fashionable\", \"record\", \"official\", \"final\", \"usual\", \"clothing\", \"educational\", \"fashion\", \"journey\"\\n\\npick three distractors from **Candidate Pool** for stem given in Original Sentence, response each distractors per line, and starts with enumerate number'}, {'role': 'assistant', 'content': '1. journey\\n2. traffic\\n3. record'}, {'role': 'user', 'content': '**Original Sentence**\\nMaria didn\\'t want to deliver the bad news to David about his failing the job interview. She herself was quite _____ about it.\\n\\n**Target Word**\\nupset\\n\\n**Candidate Pool**\\n\"curious\", \"careful\", \"excited\", \"happy\", \"afraid\", \"drowsy\", \"interested\", \"serious\", \"nervous\", \"concerned\", \"angry\", \"crazy\", \"sorry\", \"awful\", \"tired\", \"sure\", \"surprised\", \"upset\", \"good\", \"honest\", \"tragic\", \"terrible\", \"proud\", \"scared\", \"pleased\", \"strict\"\\n  \\npick three distractors from **Candidate Pool** for stem given in Original Sentence, response each distractors per line, and starts with enumerate number\\n'}, {'role': 'assistant', 'content': '1. awful\\n2. drowsy\\n3. tragic'}, {'role': 'user', 'content': \"**Original Sentence**\\n    The newcomer speaks with a strong Irish _____; he must be from Ireland.\\n    \\n**Target Word**\\naccent\\n    \\n\\n**Candidate Pool**\\n'desire', 'accents', 'warning', 'chat', 'talent', 'faith', 'presence', 'usage', 'yell', 'background', 'warmth', 'rush', 'confidence', 'remark', 'tune', 'characteristic', 'version', 'comment', 'explanation', 'theme', 'response', 'variety', 'flavor', 'suggestion', 'humor', 'impression', 'cough', 'pace', 'scream', 'laughter', 'sigh', 'signal', 'breath', 'gesture', 'accent'\\n\\npick 3 distractors from **Candidate Pool** section for stem given in Original Sentence, response each distractors per line, and starts with enumerate number. Please select your response from words in section **Candidate Pool** only.\"}]\n",
      "Assistent: 1. laughter\n",
      "2. suggestion\n",
      "3. signal\n",
      "Prompt Example:\n",
      "[{'role': 'user', 'content': '**Original Sentence**\\nPosters of the local rock band were displayed in store windows to promote the sale of their _____ tickets.\\n\\n**Target Word**\\nconcert\\n\\n**Candidate Pool**\\n\"sports\", \"proper\", \"regular\", \"personal\", \"clothes\", \"favorite\", \"traffic\", \"traditional\", \"valuable\", \"available\", \"travel\", \"necessary\", \"fashionable\", \"record\", \"official\", \"final\", \"usual\", \"clothing\", \"educational\", \"fashion\", \"journey\"\\n\\npick three distractors from **Candidate Pool** for stem given in Original Sentence, response each distractors per line, and starts with enumerate number'}, {'role': 'assistant', 'content': '1. journey\\n2. traffic\\n3. record'}, {'role': 'user', 'content': '**Original Sentence**\\nMaria didn\\'t want to deliver the bad news to David about his failing the job interview. She herself was quite _____ about it.\\n\\n**Target Word**\\nupset\\n\\n**Candidate Pool**\\n\"curious\", \"careful\", \"excited\", \"happy\", \"afraid\", \"drowsy\", \"interested\", \"serious\", \"nervous\", \"concerned\", \"angry\", \"crazy\", \"sorry\", \"awful\", \"tired\", \"sure\", \"surprised\", \"upset\", \"good\", \"honest\", \"tragic\", \"terrible\", \"proud\", \"scared\", \"pleased\", \"strict\"\\n  \\npick three distractors from **Candidate Pool** for stem given in Original Sentence, response each distractors per line, and starts with enumerate number\\n'}, {'role': 'assistant', 'content': '1. awful\\n2. drowsy\\n3. tragic'}, {'role': 'user', 'content': \"**Original Sentence**\\n    The newcomer speaks with a strong Irish _____; he must be from Ireland.\\n    \\n**Target Word**\\naccent\\n    \\n\\n**Candidate Pool**\\n'desire', 'accents', 'warning', 'chat', 'talent', 'faith', 'presence', 'usage', 'yell', 'background', 'warmth', 'rush', 'confidence', 'remark', 'tune', 'characteristic', 'version', 'comment', 'explanation', 'theme', 'response', 'variety', 'flavor', 'humor', 'impression', 'cough', 'pace', 'scream', 'sigh', 'breath', 'gesture', 'accent'\\n\\npick 3 distractors from **Candidate Pool** section for stem given in Original Sentence, response each distractors per line, and starts with enumerate number. Please select your response from words in section **Candidate Pool** only.\"}]\n",
      "Assistent: 1. flavor\n",
      "2. pace\n",
      "3. cough\n",
      "Prompt Example:\n",
      "[{'role': 'user', 'content': '**Original Sentence**\\nPosters of the local rock band were displayed in store windows to promote the sale of their _____ tickets.\\n\\n**Target Word**\\nconcert\\n\\n**Candidate Pool**\\n\"sports\", \"proper\", \"regular\", \"personal\", \"clothes\", \"favorite\", \"traffic\", \"traditional\", \"valuable\", \"available\", \"travel\", \"necessary\", \"fashionable\", \"record\", \"official\", \"final\", \"usual\", \"clothing\", \"educational\", \"fashion\", \"journey\"\\n\\npick three distractors from **Candidate Pool** for stem given in Original Sentence, response each distractors per line, and starts with enumerate number'}, {'role': 'assistant', 'content': '1. journey\\n2. traffic\\n3. record'}, {'role': 'user', 'content': '**Original Sentence**\\nMaria didn\\'t want to deliver the bad news to David about his failing the job interview. She herself was quite _____ about it.\\n\\n**Target Word**\\nupset\\n\\n**Candidate Pool**\\n\"curious\", \"careful\", \"excited\", \"happy\", \"afraid\", \"drowsy\", \"interested\", \"serious\", \"nervous\", \"concerned\", \"angry\", \"crazy\", \"sorry\", \"awful\", \"tired\", \"sure\", \"surprised\", \"upset\", \"good\", \"honest\", \"tragic\", \"terrible\", \"proud\", \"scared\", \"pleased\", \"strict\"\\n  \\npick three distractors from **Candidate Pool** for stem given in Original Sentence, response each distractors per line, and starts with enumerate number\\n'}, {'role': 'assistant', 'content': '1. awful\\n2. drowsy\\n3. tragic'}, {'role': 'user', 'content': \"**Original Sentence**\\n    The newcomer speaks with a strong Irish _____; he must be from Ireland.\\n    \\n**Target Word**\\naccent\\n    \\n\\n**Candidate Pool**\\n'desire', 'accents', 'warning', 'chat', 'talent', 'faith', 'presence', 'usage', 'yell', 'background', 'warmth', 'rush', 'confidence', 'remark', 'tune', 'characteristic', 'version', 'comment', 'explanation', 'theme', 'response', 'variety', 'humor', 'impression', 'scream', 'sigh', 'breath', 'gesture', 'accent'\\n\\npick 3 distractors from **Candidate Pool** section for stem given in Original Sentence, response each distractors per line, and starts with enumerate number. Please select your response from words in section **Candidate Pool** only.\"}]\n",
      "Assistent: 1. comment\n",
      "2. explanation\n",
      "3. humor\n",
      "Prompt Example:\n",
      "[{'role': 'user', 'content': '**Original Sentence**\\nPosters of the local rock band were displayed in store windows to promote the sale of their _____ tickets.\\n\\n**Target Word**\\nconcert\\n\\n**Candidate Pool**\\n\"sports\", \"proper\", \"regular\", \"personal\", \"clothes\", \"favorite\", \"traffic\", \"traditional\", \"valuable\", \"available\", \"travel\", \"necessary\", \"fashionable\", \"record\", \"official\", \"final\", \"usual\", \"clothing\", \"educational\", \"fashion\", \"journey\"\\n\\npick three distractors from **Candidate Pool** for stem given in Original Sentence, response each distractors per line, and starts with enumerate number'}, {'role': 'assistant', 'content': '1. journey\\n2. traffic\\n3. record'}, {'role': 'user', 'content': '**Original Sentence**\\nMaria didn\\'t want to deliver the bad news to David about his failing the job interview. She herself was quite _____ about it.\\n\\n**Target Word**\\nupset\\n\\n**Candidate Pool**\\n\"curious\", \"careful\", \"excited\", \"happy\", \"afraid\", \"drowsy\", \"interested\", \"serious\", \"nervous\", \"concerned\", \"angry\", \"crazy\", \"sorry\", \"awful\", \"tired\", \"sure\", \"surprised\", \"upset\", \"good\", \"honest\", \"tragic\", \"terrible\", \"proud\", \"scared\", \"pleased\", \"strict\"\\n  \\npick three distractors from **Candidate Pool** for stem given in Original Sentence, response each distractors per line, and starts with enumerate number\\n'}, {'role': 'assistant', 'content': '1. awful\\n2. drowsy\\n3. tragic'}, {'role': 'user', 'content': \"**Original Sentence**\\n    The newcomer speaks with a strong Irish _____; he must be from Ireland.\\n    \\n**Target Word**\\naccent\\n    \\n\\n**Candidate Pool**\\n'desire', 'accents', 'warning', 'chat', 'talent', 'faith', 'presence', 'usage', 'yell', 'background', 'warmth', 'rush', 'confidence', 'remark', 'tune', 'characteristic', 'version', 'theme', 'response', 'variety', 'impression', 'scream', 'sigh', 'breath', 'gesture', 'accent'\\n\\npick 3 distractors from **Candidate Pool** section for stem given in Original Sentence, response each distractors per line, and starts with enumerate number. Please select your response from words in section **Candidate Pool** only.\"}]\n",
      "Assistent: 1. breath\n",
      "2. sigh\n",
      "3. scream\n",
      "Prompt Example:\n",
      "[{'role': 'user', 'content': '**Original Sentence**\\nPosters of the local rock band were displayed in store windows to promote the sale of their _____ tickets.\\n\\n**Target Word**\\nconcert\\n\\n**Candidate Pool**\\n\"sports\", \"proper\", \"regular\", \"personal\", \"clothes\", \"favorite\", \"traffic\", \"traditional\", \"valuable\", \"available\", \"travel\", \"necessary\", \"fashionable\", \"record\", \"official\", \"final\", \"usual\", \"clothing\", \"educational\", \"fashion\", \"journey\"\\n\\npick three distractors from **Candidate Pool** for stem given in Original Sentence, response each distractors per line, and starts with enumerate number'}, {'role': 'assistant', 'content': '1. journey\\n2. traffic\\n3. record'}, {'role': 'user', 'content': '**Original Sentence**\\nMaria didn\\'t want to deliver the bad news to David about his failing the job interview. She herself was quite _____ about it.\\n\\n**Target Word**\\nupset\\n\\n**Candidate Pool**\\n\"curious\", \"careful\", \"excited\", \"happy\", \"afraid\", \"drowsy\", \"interested\", \"serious\", \"nervous\", \"concerned\", \"angry\", \"crazy\", \"sorry\", \"awful\", \"tired\", \"sure\", \"surprised\", \"upset\", \"good\", \"honest\", \"tragic\", \"terrible\", \"proud\", \"scared\", \"pleased\", \"strict\"\\n  \\npick three distractors from **Candidate Pool** for stem given in Original Sentence, response each distractors per line, and starts with enumerate number\\n'}, {'role': 'assistant', 'content': '1. awful\\n2. drowsy\\n3. tragic'}, {'role': 'user', 'content': \"**Original Sentence**\\n    The newcomer speaks with a strong Irish _____; he must be from Ireland.\\n    \\n**Target Word**\\naccent\\n    \\n\\n**Candidate Pool**\\n'desire', 'accents', 'warning', 'chat', 'talent', 'faith', 'presence', 'usage', 'yell', 'background', 'warmth', 'rush', 'confidence', 'remark', 'tune', 'characteristic', 'version', 'theme', 'response', 'variety', 'impression', 'gesture', 'accent'\\n\\npick 3 distractors from **Candidate Pool** section for stem given in Original Sentence, response each distractors per line, and starts with enumerate number. Please select your response from words in section **Candidate Pool** only.\"}]\n",
      "Assistent: 1. desire\n",
      "2. chat\n",
      "3. remark\n",
      "good: ['concept', 'pronunciation', 'sigh', 'rhythm', 'dialect', 'chat', 'flavor', 'strength', 'vocabulary', 'desire', 'pace', 'cough', 'explanation', 'attitude', 'performance', 'jazz', 'signal', 'rate', 'humor', 'whistle', 'laughter', 'remark', 'scream', 'behavior', 'comment', 'signature', 'complaint', 'suggestion', 'grammar', 'breath']\n",
      "bad: []\n",
      "1\n",
      "The word 'attached' picked by LLM does not exist in candidate list, may it because the low size of candidate pool?\n",
      "The word 'adapted' picked by LLM does not exist in candidate list, may it because the low size of candidate pool?\n",
      "The word 'confined' picked by LLM does not exist in candidate list, may it because the low size of candidate pool?\n",
      "The word 'attached' picked by LLM does not exist in candidate list, may it because the low size of candidate pool?\n",
      "The word 'contributed' picked by LLM does not exist in candidate list, may it because the low size of candidate pool?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# dis_model = DistractorGenerationModel(config, preprocess_function, few_shot, self_answer)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m dis_model \u001b[38;5;241m=\u001b[39m DistractorGenerationModel(config, preprocess_function, few_shot, self_answer)\n\u001b[0;32m---> 28\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mdis_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_framework\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 235\u001b[0m, in \u001b[0;36mDistractorGenerationModel.run_framework\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Self-answer\u001b[39;00m\n\u001b[0;32m--> 235\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_processing_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistractor_pool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m generate_history \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    237\u001b[0m t \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/mnt/NAS/ycliu/temp/ISSR/Code/postprocess.py:134\u001b[0m, in \u001b[0;36mself_answer\u001b[0;34m(self, question, distractor_pool)\u001b[0m\n\u001b[1;32m    132\u001b[0m send_prompt \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{OPTION1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, options[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{OPTION2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, options[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mappend_chat(send_prompt, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 134\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLLM_config\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Gpt refuse to answer\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm sorry\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response:\n",
      "File \u001b[0;32m/mnt/NAS/ycliu/temp/ISSR/Code/models.py:57\u001b[0m, in \u001b[0;36mopenAIModel.inference\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify_using_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# for degugging: print the prompt sending to model\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m#self.test_prompt()\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Call GPT API and get response\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m completion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# generate one choice only\u001b[39;49;00m\n\u001b[1;32m     62\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m gpt_response \u001b[38;5;241m=\u001b[39m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# print(f\"-----[GPT]-----\\n{gpt_response}\")\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/FF/lib/python3.9/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/FF/lib/python3.9/site-packages/openai/resources/chat/completions.py:667\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    665\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    666\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 667\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/FF/lib/python3.9/site-packages/openai/_base_client.py:1208\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1195\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1196\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1203\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1204\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1205\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1206\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1207\u001b[0m     )\n\u001b[0;32m-> 1208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.conda/envs/FF/lib/python3.9/site-packages/openai/_base_client.py:897\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    890\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    895\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    896\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/FF/lib/python3.9/site-packages/openai/_base_client.py:926\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    923\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauth\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_auth\n\u001b[1;32m    925\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 926\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    932\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/FF/lib/python3.9/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/.conda/envs/FF/lib/python3.9/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/FF/lib/python3.9/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.conda/envs/FF/lib/python3.9/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/.conda/envs/FF/lib/python3.9/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    242\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/FF/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m~/.conda/envs/FF/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/.conda/envs/FF/lib/python3.9/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/FF/lib/python3.9/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/.conda/envs/FF/lib/python3.9/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/.conda/envs/FF/lib/python3.9/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/FF/lib/python3.9/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/.conda/envs/FF/lib/python3.9/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/FF/lib/python3.9/ssl.py:1260\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1257\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1258\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1259\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/.conda/envs/FF/lib/python3.9/ssl.py:1135\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "from preprocess import *\n",
    "from distractor_generation import *\n",
    "from utils import *\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = get_config()\n",
    "    print(config)\n",
    "    if(config['preprocess_function']['mode'] == \"BERT\") or config['preprocess_function']['mode'] == \"CDGP\":\n",
    "        preprocess_function = pool_generation\n",
    "    elif(config['preprocess_function']['mode'] == \"reason\"):\n",
    "        preprocess_function = reason_generation\n",
    "    elif(config['preprocess_function']['mode'] == \"None\"):\n",
    "        preprocess_function = none\n",
    "    else:\n",
    "        preprocess_function = pool_generation\n",
    "\n",
    "\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('omw-1.4')\n",
    "\n",
    "\n",
    "    \n",
    "    # dis_model = DistractorGenerationModel(config, preprocess_function, few_shot, self_answer)\n",
    "    dis_model = DistractorGenerationModel(config, preprocess_function, few_shot, self_answer)\n",
    "    result = dis_model.run_framework()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt_pickRate3_CDGP_fewshot_selfanswer.json'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Format: {distractor_selector_model}_{distractors picked per round}_{candidate generator}_{fewshot or zeroshot}_{self-review or not}.json\n",
    "'''\n",
    "result_path = f\"\"\"{config['LLM']}_pickRate{config['distractor_generation_function'][\"pick_distractors_per_round\"]}_{config['preprocess_function']['mode']}_{'fewshot' if config['distractor_generation_function']['zero-shot'] == False else 'zeroshot'}_{'selfanswer' if config['post_processing_function']['self-answer'] == True else 'none'}.json\"\"\"\n",
    "result_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing to ./result/gpt_pickRate3_CDGP_fewshot_selfanswer.json\n"
     ]
    }
   ],
   "source": [
    "result_path = f\"\"\"./result/{config['LLM']}_pickRate{config['distractor_generation_function'][\"pick_distractors_per_round\"]}_{config['preprocess_function']['mode']}_{'fewshot' if config['distractor_generation_function']['zero-shot'] == False else 'zeroshot'}_{'selfanswer' if config['post_processing_function']['self-answer'] == True else 'none'}.json\"\"\"\n",
    "\n",
    "with open(result_path, 'w') as f:\n",
    "    print(f\"writing to {result_path}\")\n",
    "    json.dump(dis_model.dataset, f, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FF",
   "language": "python",
   "name": "ff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
